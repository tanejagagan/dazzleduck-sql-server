 dazzleduck_server = {
    flight_sql = {
        port = 59307
        host = "0.0.0.0"
        use_encryption = true
    }

#    http = {
#       port = 8081
#        host = "0.0.0.0"
#       authentication = "none"
#    }

    keystore = "security/server0.key"
    server_cert = "security/server0.pem"
    secret_key = "VGhpcyBpcyBhIDY0IGJpdCBsb25nIGtleSB3aGljaCBzaG91bGQgYmUgY2hhbmdlZCBpbiBwcm9kdWN0aW9uLiBTbyBjaGFuZ2UgbWUgYW5kIG1ha2Ugc3VyZSBpdHMgMTI4IGJpdCBsb25nIG9yIG1vcmU"
    producer_id = "dazzleduck-flight-server"
    temp_write_location = "/tmp/dazzleduck-writes"
    warehouse = ${user.dir}"/warehouse"

    # Maximum time in milliseconds a query can run before being automatically cancelled
    query_timeout_ms = 120000 // 2 minutes

    ingestion = {
        min_bucket_size = 1048576 // 1MB
        max_delay_ms = 2000 // 2 sec
    }
    users = [{
        username = admin
        password = admin
        groups = [admin, general]
    }, {
        username = restricted_user
        password = password
        groups = [restricted]
    }]
    jwt_token = {
        expiration = 60m
        claims.generate.headers = [database,schema,table,filter,path,function,access_type]
        claims.validate.headers = []
        generation = true
    }

    # Uncomment this  if you want jwt token generation and user/password validation done by external login server
    # This will start proxy all the login/authentication requests to this url
    #login_url = "http://localhost:8080/login"

    # values COMPLETE, RESTRICTED
    access_mode = COMPLETE

    startup_script_provider = {
        class = "io.dazzleduck.sql.common.ConfigBasedStartupScriptProvider"
        content = """
        INSTALL arrow FROM community;
        load arrow;
        """
        # location of the file. If both content and location is provided then content and location are appended to each  other
        # script_location = "/path/to/file.sql"
    }

    post_ingestion_task_factory_provider {
       class = "io.dazzleduck.sql.commons.ingestion.DuckLakePostIngestionTaskFactoryProvider"
    }

 # post_ingestion_task_factory_provider {
   #       class = "io.dazzleduck.sql.commons.ingestion.DuckLakePostIngestionTaskFactoryProvider"
   #       catalog_name = "my_ducklake"
       #   path_to_table_mapping = [
   #       {
  #            table_name = "log"
  #            schema_name = "main"
 #             base_path = "log"
  #        },
  #        {
  #          table_name = "metric"
  #          schema_name = "main"
  #          base_path = "metric"
  #        }
  #        ]
 #     }

    # Enable this while using ducklake
    #    post_ingestion_task_factory_provider {
    #      # Use DucklakePostIngestionTaskFactoryProvider for DuckLake integration
    #      provider_class = "io.dazzleduck.sql.commons.ingestion.DuckLakePostIngestionTaskFactoryProvider"
    #
    #      # Database configuration
    #      database = "main"
    #
    #      # Path to table mapping
    #      path_to_table_mapping {
    #        table_name = test_table
    #        schema_name = "main"
    #        # base_path should be the relative path to the warehouse
    #        base_path = "logs"
    #      }
    #    }


    query_optimizer_provider = {
           class = io.dazzleduck.sql.flight.optimizer.QueryOptimizerProvider
    }
}